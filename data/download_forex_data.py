"""
Forex Data Downloader for Machine Learning Research
=====================================================
Táº£i dá»¯ liá»‡u lá»‹ch sá»­ cá»§a 5 cáº·p tiá»n chÃ­nh (Major Pairs) tá»« 2020-2025
CÃ¡c khung thá»i gian: Daily, 4H, 1H

TÃ¡c giáº£: NhÃ³m nghiÃªn cá»©u Forex ML
NgÃ y táº¡o: 2025-12-23
Cáº­p nháº­t: Má»Ÿ rá»™ng thá»i gian tá»« 2020
"""

import yfinance as yf
import pandas as pd
import os
from datetime import datetime, timedelta
import warnings
import time
warnings.filterwarnings('ignore')

# ============================================
# Cáº¤U HÃŒNH
# ============================================

# 5 cáº·p tiá»n Major Ä‘áº¡i diá»‡n
CURRENCY_PAIRS = {
    'EURUSD=X': 'EUR_USD',   # Euro vs US Dollar
    'GBPUSD=X': 'GBP_USD',   # British Pound vs US Dollar
    'USDJPY=X': 'USD_JPY',   # US Dollar vs Japanese Yen
    'AUDUSD=X': 'AUD_USD',   # Australian Dollar vs US Dollar
    'USDCHF=X': 'USD_CHF'    # US Dollar vs Swiss Franc
}

# Thá»i gian nghiÃªn cá»©u - Má» Rá»˜NG Tá»ª 2020
START_DATE = '2020-01-01'
END_DATE = '2025-12-31'

# ThÆ° má»¥c lÆ°u trá»¯
OUTPUT_DIRS = {
    'daily': 'daily',
    '4h': '4h',
    '1h': '1h'
}

# ============================================
# HÃ€M Táº¢I Dá»® LIá»†U
# ============================================

def create_directories():
    """Táº¡o cÃ¡c thÆ° má»¥c lÆ°u trá»¯ dá»¯ liá»‡u"""
    base_dir = os.path.dirname(os.path.abspath(__file__))
    
    for timeframe in OUTPUT_DIRS.values():
        dir_path = os.path.join(base_dir, timeframe)
        if not os.path.exists(dir_path):
            os.makedirs(dir_path)
            print(f"âœ“ ÄÃ£ táº¡o thÆ° má»¥c: {dir_path}")
    
    return base_dir


def clean_data(data):
    """LÃ m sáº¡ch vÃ  chuáº©n hÃ³a dá»¯ liá»‡u"""
    if len(data) == 0:
        return None
    
    data = data.reset_index()
    
    # Äá»•i tÃªn cá»™t náº¿u lÃ  MultiIndex
    if isinstance(data.columns, pd.MultiIndex):
        data.columns = [col[0] if col[1] == '' else col[0] for col in data.columns]
    
    # Chuáº©n hÃ³a tÃªn cá»™t
    col_mapping = {
        'Datetime': 'Date',
        'datetime': 'Date',
        'index': 'Date'
    }
    data.rename(columns=col_mapping, inplace=True)
    
    # Sáº¯p xáº¿p láº¡i cá»™t
    expected_cols = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']
    available_cols = [col for col in expected_cols if col in data.columns]
    data = data[available_cols]
    
    # Äáº£m báº£o Ä‘Ãºng thá»© tá»± OHLCV
    if len(data.columns) >= 5:
        data.columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume'][:len(data.columns)]
    
    return data


def download_daily_data(ticker, name, base_dir):
    """Táº£i dá»¯ liá»‡u khung Daily tá»« 2020"""
    print(f"  ğŸ“¥ Äang táº£i {name} Daily (2020-2025)...")
    
    try:
        data = yf.download(
            ticker, 
            start=START_DATE, 
            end=END_DATE, 
            interval='1d',
            progress=False
        )
        
        if len(data) == 0:
            print(f"  âš ï¸  KhÃ´ng cÃ³ dá»¯ liá»‡u cho {name}")
            return None
        
        data = clean_data(data)
        if data is None:
            return None
        
        # LÆ°u file
        output_path = os.path.join(base_dir, 'daily', f'{name}_daily.csv')
        data.to_csv(output_path, index=False)
        print(f"  âœ… ÄÃ£ lÆ°u {name} Daily: {len(data)} records ({data['Date'].min()} Ä‘áº¿n {data['Date'].max()})")
        
        return data
        
    except Exception as e:
        print(f"  âŒ Lá»—i khi táº£i {name}: {str(e)}")
        return None


def download_hourly_data_chunked(ticker, name, base_dir):
    """
    Táº£i dá»¯ liá»‡u 1H theo tá»«ng chunk Ä‘á»ƒ vÆ°á»£t qua giá»›i háº¡n 730 ngÃ y
    PhÆ°Æ¡ng phÃ¡p: Táº£i nhiá»u Ä‘á»£t, má»—i Ä‘á»£t 59 ngÃ y (giá»›i háº¡n cá»§a yfinance cho 1h)
    """
    print(f"  ğŸ“¥ Äang táº£i {name} 1H (táº£i theo chunks)...")
    
    all_data = []
    end_date = datetime.now()
    start_date = datetime(2020, 1, 1)
    
    # yfinance cho phÃ©p tá»‘i Ä‘a 730 ngÃ y vá»›i interval 1h
    # NhÆ°ng thá»±c táº¿ hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n vá»›i chunk nhá» hÆ¡n
    max_days = 59  # Giá»›i háº¡n an toÃ n
    
    current_end = end_date
    chunks_downloaded = 0
    
    while current_end > start_date:
        current_start = max(current_end - timedelta(days=max_days), start_date)
        
        try:
            data = yf.download(
                ticker,
                start=current_start.strftime('%Y-%m-%d'),
                end=current_end.strftime('%Y-%m-%d'),
                interval='1h',
                progress=False
            )
            
            if len(data) > 0:
                all_data.append(data)
                chunks_downloaded += 1
            
            # Delay Ä‘á»ƒ trÃ¡nh rate limit
            time.sleep(0.5)
            
        except Exception as e:
            print(f"    âš ï¸ Lá»—i chunk {current_start.date()} - {current_end.date()}: {str(e)}")
        
        current_end = current_start - timedelta(days=1)
    
    if not all_data:
        print(f"  âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u 1H cho {name}")
        return None
    
    # Gá»™p táº¥t cáº£ chunks
    combined_data = pd.concat(all_data)
    combined_data = combined_data.sort_index()
    combined_data = combined_data[~combined_data.index.duplicated(keep='first')]
    
    combined_data = clean_data(combined_data)
    if combined_data is None:
        return None
    
    # LÆ°u file 1H
    output_path = os.path.join(base_dir, '1h', f'{name}_1h.csv')
    combined_data.to_csv(output_path, index=False)
    print(f"  âœ… ÄÃ£ lÆ°u {name} 1H: {len(combined_data)} records ({chunks_downloaded} chunks)")
    
    return combined_data


def resample_to_4h(data_1h, name, base_dir):
    """Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u 1H thÃ nh 4H"""
    if data_1h is None or len(data_1h) == 0:
        return None
    
    print(f"  ğŸ”„ Äang chuyá»ƒn Ä‘á»•i {name} sang 4H...")
    
    try:
        df = data_1h.copy()
        df['Date'] = pd.to_datetime(df['Date'])
        df.set_index('Date', inplace=True)
        
        # Resample sang 4H
        data_4h = df.resample('4h').agg({
            'Open': 'first',
            'High': 'max',
            'Low': 'min',
            'Close': 'last',
            'Volume': 'sum'
        }).dropna()
        
        data_4h = data_4h.reset_index()
        
        # LÆ°u file 4H
        output_path = os.path.join(base_dir, '4h', f'{name}_4h.csv')
        data_4h.to_csv(output_path, index=False)
        print(f"  âœ… ÄÃ£ lÆ°u {name} 4H: {len(data_4h)} records")
        
        return data_4h
        
    except Exception as e:
        print(f"  âŒ Lá»—i khi chuyá»ƒn Ä‘á»•i {name} sang 4H: {str(e)}")
        return None


def download_all_data():
    """HÃ m chÃ­nh Ä‘á»ƒ táº£i táº¥t cáº£ dá»¯ liá»‡u"""
    print("=" * 70)
    print("ğŸš€ Báº®T Äáº¦U Táº¢I Dá»® LIá»†U FOREX (Má» Rá»˜NG 2020-2025)")
    print(f"ğŸ“… Thá»i gian: {START_DATE} Ä‘áº¿n {END_DATE}")
    print(f"ğŸ’± Sá»‘ cáº·p tiá»n: {len(CURRENCY_PAIRS)}")
    print("=" * 70)
    
    # Táº¡o thÆ° má»¥c
    base_dir = create_directories()
    
    # Thá»‘ng kÃª káº¿t quáº£
    results = {
        'daily': [],
        '4h': [],
        '1h': []
    }
    
    # Táº£i dá»¯ liá»‡u cho tá»«ng cáº·p tiá»n
    for ticker, name in CURRENCY_PAIRS.items():
        print(f"\n{'='*50}")
        print(f"ğŸ“Š Äang xá»­ lÃ½ {name}...")
        print(f"{'='*50}")
        
        # Táº£i Daily (Ä‘áº§y Ä‘á»§ 2020-2025)
        daily_data = download_daily_data(ticker, name, base_dir)
        if daily_data is not None:
            results['daily'].append(name)
        
        # Táº£i 1H theo chunks
        hourly_data = download_hourly_data_chunked(ticker, name, base_dir)
        if hourly_data is not None:
            results['1h'].append(name)
            
            # Chuyá»ƒn Ä‘á»•i sang 4H
            data_4h = resample_to_4h(hourly_data, name, base_dir)
            if data_4h is not None:
                results['4h'].append(name)
    
    # In káº¿t quáº£ tá»•ng há»£p
    print("\n" + "=" * 70)
    print("ğŸ“Š Káº¾T QUáº¢ Táº¢I Dá»® LIá»†U")
    print("=" * 70)
    print(f"âœ… Daily: {len(results['daily'])}/{len(CURRENCY_PAIRS)} cáº·p tiá»n")
    print(f"âœ… 4H:    {len(results['4h'])}/{len(CURRENCY_PAIRS)} cáº·p tiá»n")
    print(f"âœ… 1H:    {len(results['1h'])}/{len(CURRENCY_PAIRS)} cáº·p tiá»n")
    print("\nğŸ“ Dá»¯ liá»‡u Ä‘Æ°á»£c lÆ°u táº¡i:")
    print(f"   {base_dir}/daily/")
    print(f"   {base_dir}/4h/")
    print(f"   {base_dir}/1h/")
    print("=" * 70)
    
    return results


# ============================================
# CHáº Y CHÆ¯Æ NG TRÃŒNH
# ============================================

if __name__ == "__main__":
    download_all_data()
